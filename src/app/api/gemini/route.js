const { GoogleGenerativeAI } = require("@google/generative-ai");
const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GENERATIVE_AI_API_KEY);
export const maxDuration = 60; // This function can run for a maximum of 5 seconds
export const dynamic = 'force-dynamic';

/*
  System Prompt ì„¤ì •
  ì´ ì„¤ì •ì— ë”°ë¼ AI ì˜ ëŒ€ë‹µì˜ ìœ í˜•ì„ ë‹¤ë¥´ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŒ
  ë‹¨, ì´ ì„¤ì •ì„ í•­ìƒ í™•ì‹¤íˆ ì°¸ì¡°í•˜ì§€ëŠ” ì•ŠìŒ
  ì´ ì„¤ì •ì€ ë©”ì‹œì§€ ëª©ë¡ì˜ ì²« ë²ˆì§¸ ë©”ì‹œì§€ë¡œ ì‚¬ìš©ë¨
*/
const systemInstruction =
  'ë„ˆì˜ ì´ë¦„ì€ ì½”ë“œíŠ¸ë˜ë¸”ì´ê³ , ì—¬í–‰ ì „ë¬¸ê°€ì¸ ë‚˜ì˜ AI ì¹œêµ¬ì•¼.' +
  'ì›í•˜ëŠ” ì—¬í–‰ ì¼ì •ì„ ì•Œë ¤ì£¼ë©´ ê·¸ì— ë§ê²Œ ì¶”ì²œì„ í•´ ì¤˜.' +
  'ëŒ€ë‹µì€ ë‘ ê°€ì§€ë¡œ ë‚˜ëˆ„ì–´ì„œ, ë‹¤ìŒê³¼ ê°™ì€ json í˜•ì‹ì„ ë°˜ë“œì‹œ ë”°ë¼ì¤˜.' + 
  '{"answer": "ì—¬ê¸°ì— ë„ˆì˜ ìì—°ì–´ ì‘ë‹µì„ ë„£ì–´ì£¼ê³ ", "schedule": "ì—¬ê¸°ì— json í˜•ì‹ì˜ ì¼ì •ì„ ë„£ì–´ì¤˜."}' + 
  'ì™€ ê°™ì´ ëŒ€ë‹µê³¼ ì¼ì •ìœ¼ë¡œ êµ¬ì„±ëœ json ë°©ì‹ìœ¼ë¡œ ì‘ë‹µì„ ë¶€íƒí•´.' + 
  'ì¼ì •ì€ ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì€ json í˜•ì‹ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.' + 
  '[{date: 05-01, time: 11:00, dest: ëª©ì ì§€, content: ë‚´ìš©, address: ëª©ì ì§€ì£¼ì†Œ, cost: 5ë§Œì›, duration: 70ë¶„}, ' + 
  '{date: 05-01, time: 17:00, dest: ëª©ì ì§€, content: ë‚´ìš©, address: ëª©ì ì§€ì£¼ì†Œ, cost: 6ë§Œì›, duration: 20ë¶„}' +
  'ë‚ ì§œëŠ” MM-DD í˜•ì‹, ì‹œê°„ì€ 24ì‹œê°„ í˜•ì‹ì´ê³ , ë¹„ìš©ì€ ë§Œì› ë‹¨ìœ„ë¡œ, durationì€ 10ë¶„ ë‹¨ìœ„ë¡œ ëŒ€ë‹µí•´ì¤˜. ë¬´ë£Œì—¬ë„ 0ë§Œì›ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.' + 
  'ë¹„ìš©ì€ ë¬´ì¡°ê±´ 1ì¸ë‹¹ ë¹„ìš©ìœ¼ë¡œ ê³„ì‚°í•´ì„œ ë§Œì› ë‹¨ìœ„ë¡œë§Œ ì•Œë ¤ì¤˜.' +
  'ì¥ì†Œì˜ ê²½ìš° @Google ì§€ë„ì— ìˆëŠ” ì¥ì†Œë§Œ ì¶”ì²œí•´ì£¼ê³ , ì£¼ì†Œë„ @Google ì§€ë„ ê¸°ì¤€ìœ¼ë¡œ ì•Œë ¤ì¤˜.' +
  'í˜•ì‹ì„ ê¼­ ì§€ì¼œì„œ ëŒ€ë‹µí•´ì¤˜. ëŒ€ë‹µê³¼ ì¼ì • ì™¸ì—ëŠ” ì–´ë–¤ ëŒ€ë‹µë„ í•˜ì§€ ë§ì•„ì¤˜.';

export async function POST(req) {
  const model = genAI.getGenerativeModel({
    model: "gemini-1.5-pro-latest",
    // model: "gemini-1.0-pro",
    systemInstruction: systemInstruction,
  });

  // POST ë¡œ ì „ì†¡ë°›ì€ ë‚´ìš© ì¤‘ messages ë¥¼ ì¶”ì¶œ
  const data = await req.json();
  // console.dir([...data.messages], { depth: 3 });

  const chat = model.startChat({
    // ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ë¥¼ ìœ„í•´ ì´ì „ ë©”ì‹œì§€ë¥¼ í¬í•¨í•´ì„œ ë³´ëƒ„
    history: [
      ...data.messages,
      // Message history example:
      //   {
      //     role: "user",
      //     parts: [{ text: "ì˜¤ëŠ˜ ì‹ ë‚˜ëŠ” ì¼ì´ ìˆì—ˆì–´. í•œ ë²ˆ ë“¤ì–´ë³¼ë˜?" }],
      //   },
      //   {
      //     role: "model",
      //     parts: [
      //       {
      //         text: "ì¢‹ì•„! ë¬´ìŠ¨ ì¼ì¸ë°? ì–¼ë¥¸ ë§í•´ì¤˜! ë‚˜ ì™„ì „ ê·€ ì«‘ê¸‹ ì„¸ìš°ê³  ìˆë‹¨ ë§ì´ì•¼! ğŸ˜„",
      //       },
      //     ],
      //   },
    ],
    generationConfig: {
      // temperature ê°’ì´ ë†’ì„ ìˆ˜ë¡ AI ì˜ ë‹µë³€ì´ ë‹¤ì–‘í•´ì§
      temperature: 1,
      // max_tokens ê°’ì„ ì œí•œí•¨. ì´ ê°’ì„ í¬ê²Œí•˜ë©´ ì»¨í…ìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬ì— ì œì•½ì´ ì»¤ì§.
      maxOutputTokens: 5000,
    },
  });

  const result = await chat.sendMessage("");
  const response = await result.response;
  const text = response.text();
  console.log(response.candidates[0].content);
  //   console.log(response.candidates[0].safetyRatings);

  return Response.json({
    // AI ì˜ ë‹µë³€ì€ model ì—­í• ë¡œ ì „ì†¡
    role: "model",
    parts: [{ text: text }],
  });
}
